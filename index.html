<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet">
  <title>My Portfolio</title>
</head>
<body>

  <header class="bg-light py-3">
    <h1 class="text-center">My Portfolio</h1>
  </header>

  <section class="container my-5" id="info">
    <h2>Basic Information</h2>
    <p>Name: Lenart Lavrih</p>
    <p>Email: lenart@lavrih.com</p>
  </section>

  <section class="container my-5" id="skills">
    <h2>Skills</h2>
    <div class="row">
      <div class="col-md-4">
        <h3>Programming</h3>
        <ul>
          <li>Python</li>
          <li>C++</li>
          <li>ROS1</li>
          <li>ROS2</li>
        </ul>
      </div>
      <div class="col-md-4">
        <h3>Operating Systems</h3>
        <ul>
          <li>Linux</li>
          <li>MacOS</li>
          <li>Windows</li>
        </ul>
      </div>
      <div class="col-md-4">
        <h3>Software & Tools</h3>
        <ul>
          <li>Visualisation (matplotlib, RViZ)</li>
          <li>Simulation (Gazebo, Matlab)</li>
          <li>Point Cloud processing (Open3D, numpy)</li>
          <li>Git</li>
          <li>Office</li>
        </ul>
      </div>
    </div>
  </section>

  <section class="container my-5" id="projects">
    <h2>Projects</h2>
    <div class="row">
      <div class="col-md-4">
        <h3>Framework Migration of Robotic System from ROS1 to ROS2</h3>
        <p>In March 2022, I embarked on a project to migrate a hobby robot's framework from ROS1 Melodic to ROS2 Humble. My first step was to create a custom URDF file to accurately represent the robot's structure and dimensions. Subsequently, I gained foundational knowledge in ROS1 and applied it to transition the system to ROS2. For motion planning, I utilized MoveIt, and for visualization and goal-setting, I used RViz.</p>
      </div>
      <div class="col-md-4">
        <h3>Digital twin in ROS1</h3>
        <p>In a separate project, I created a digital twin of a UR5 robot using ROS1 Noetic. The real-world robot and its simulation in Gazebo were both equipped with 8 LiDAR sensors. The simulation ran in real-time, synchronized through RTDE (Real-Time Data Exchange). Through a series of tests, we evaluated and compared sensor readings in both the simulated and real-world environments.</p>
      </div>
      <div class="col-md-4">
        <h3>Master thesis</h3>
        <p>In this master's thesis, the integration of two cameras on an autonomous mobile robot is presented, as well as the development and testing of an obstacle detection algorithm. The primary objectives were to determine the best camera placement for capturing the visible area during driving and to develop an efficient algorithm for environmental perception.

          First, we analyzed the market and existing solutions in the literature, defined system requirements, studied the characteristics of depth cameras, and developed a mathematical model to calculate the cameras' field of view. This model was used to study various camera placements and determine the optimal positioning. A significant portion of the thesis focused on the development of the obstacle detection algorithm in the environment.
          
          We used the Intel RealSense D435f stereo cameras for environmental capture. The entire architecture is based on the open-source ROS environment and the Python language. The primary library for processing camera data was Open3d, while visualization was handled with RViz. Additionally, we explored a method for plane detection using a GPU, which enabled faster data processing. Based on these results, we developed an optimal algorithm for obstacle detection, which was then tested on the AMR.
          
          The research results include an analysis of environmental obstacle detection, measuring the standard deviation of distance, ground obstacle detection resolution, and repeatability of obstacle detection in a specific zone. Testing of different obstacle materials and obstacle detection during driving was also included.
          
          The discussion focuses on addressing potential issues that arose during the study. Challenges such as glare problems, detecting airborne obstacles, camera positioning, and possible improvements are highlighted.</p>
      </div>
    </div>
  </section>

  <!-- Bootstrap JS (Optional) -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.bundle.min.js"></script>

</body>
</html>
